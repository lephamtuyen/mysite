<!DOCTYPE html>
<html lang="en" class="gr__cims_nyu_edu"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="Tuyen P. Le personal website">
	<meta name="author" content="Tuyen P. Le">

	<title>HDRQN</title>

	<!-- Bootstrap core CSS -->
	<link href="./hdrqn/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="./hdrqn/bootstrap-social.css">
	<style type="text/css">
	</style>
	<style>
  	* {
   		margin: 0;
   		padding: 0;
  	}
  	.imgbox {
   		display: grid;
   		height: 100%;
  	}
  	.center-fit {
   		max-width: 100%;
   		max-height: 100vh;
   		margin: auto;
  	}
  	</style>
</head>
<body data-gr-c-s-loaded="true">
	<div class="container">
		<h1 class="text-center">
			Deep Hierarchical Reinforcement Learning Algorithm in Partially Observable Markov Decision Processes<br>
			<small>Tuyen P. Le and Ngo Anh Vien and TaeChoong Chung</small>
            <br>
            <br>
            <img class="center-fit" src="./hdrqn/abstract.png">
		</h1>
		<hr>
		<p class="lead">
		  In recent years, reinforcement learning has achieved many remarkable successes due to the growing adoption of deep learning techniques and the rapid growth in computing power. Nevertheless, it is well-known that flat reinforcement learning algorithms are often not able to learn well and data-efficient in tasks having hierarchical structures, e.g. consisting of multiple subtasks. Hierarchical reinforcement learning is a principled approach that is able to tackle these challenging tasks. On the other hand, many real-world tasks usually have only partial observability in which state measurements are often imperfect and partially observable. The problems of RL in such settings can be formulated as a partially observable Markov decision process (POMDP). In this paper, we study hierarchical RL in POMDP in which the tasks have only partial observability and possess hierarchical properties. We propose a hierarchical deep reinforcement learning approach for learning in hierarchical POMDP. The deep hierarchical RL algorithm is proposed to apply to both MDP and POMDP learning. We evaluate the proposed algorithm on various challenging hierarchical POMDP.
		</p>
		<p class="text-center">
			<a class="btn btn-primary btn-lg" href="https://ieeexplore.ieee.org/document/8421749" target="_blank">PDF</a>
			<a class="btn btn-default btn-lg" href="https://github.com/lephamtuyen/hdrqn" target="_blank">Code</a>
		</p>
		<hr>
		<div class="text-center">
		<iframe width="560" height="315" src="https://www.youtube.com/embed/r2wQiOc6euE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>
		</div>
		<hr>
	</div>

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script async="" src="./hdrqn/analytics.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
    <script src="./hdrqn/bootstrap.min.js"></script>

    <!-- google analyitcs -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-89717371-1', 'auto');
    ga('send', 'pageview');

    </script>


</body></html>
